---
title: "[논문리뷰] 한국어 기술문서 분석을 위한 BERT 기반의 분류모델_황상흠, 김도현"
date: 2020-08-03
category: NLP
---

# 한국어 기술문서 분석을 위한 BERT 기반의 분류모델_황상흠, 김도현

### 목적: 기술문서 분류 모델 제안
   
   - R&D 과제 정보 활용 R&D 중분류코드 예측 모델 생성
    
### 모델 - BERT fine-tuning
   
   - SKT KoBERT와 동일한 구조
    
    - DATA: 국가과학기술지식정보서비스에 등록되어 있는 기술분서 7118개 (개별 기술문서 하나의 문장으로 취급)
    
    - 전처리: 특수기호 제거, 중분류기술명이 숫자가 아닌 경우 제외 => 7108개
    
    - 70% train, 30% val
    
    - Optimizer: Adam, lr:5e-5, epoch:50, mini batch:50
    
    - 33개 중분류에 대한 이진 분류에 avg loss 계산
    
### 결과
 
 - Precision: 0.5591, Recall:0.5531, F-score:0.5531
    
    - 대략 절반 정도 맞춤

### 한계
  
    - 하나의 기술문서를 하나의 문장으로 처리
    
    - 부족한 데이터 수

## 생각

    - 이 정도의 데이터 수로도 fine-tuning이 가능한가? (fine-tuning이 가능한 최소한의 문서양은 얼마나?)
    
    - 50 epoch나 돌린 이유는 데이터 수가 부족하기 때문에 학습 스텝이 부족해서일까? 적절한 total step 수라는 게 존재하나?
    
