---
title: "Active Learning"
date: 2021-01-28
categories: AL
---

# 1. Active Learning

- Label Annotation에 들어가는 노력을 줄이기 위한 방법론
- 기존의 모델들을 활용해 unlabeled data에 대한 추론을 진행하고 불확실성이 높은 데이터를 우선적으로 **human annotator에게 Labeling을 요청**하는 방법
Random Sampling보다 더 좋은 성능
**어떠한 기준으로 해당 데이터를 선정하는지가 중요**

## Query Strategy

### 1) Uncertainty sampling

### (1) Least Confident Sampling

- 모델이 예측한 각 클래스에 속할 확률 중 Top1 확률이 가장 낮은 데이터부터 레이블링 지시

### (2) Margin Sampling

- 모델이 예측한 각 클래스에 속할 확률 중 Top1, Top2 확률의 차이가 가장 적은 데이터부터 레이블링 지시
- Binary classification에서는 LC와 동일한 결과

### (3) Entropy Sampling

- 모델이 예측한 각 클래스에 속할 확률을 이용해, 엔트로피가 가장 큰 데이터부터 레이블링 지시

### 2) Query-By-Committee

- 구성원 간의 의견 차이를 측정하는 척도

### (1) vote entropy

엔트로피 기반의 uncertainly sampling를 QBC로 일반화한 것

### (2) 평균 Kullback-Leibler(KL) divergence 기반

가장 정보량이 높은 쿼리는 라벨 분포 간의 평균적인 차이가 가장 큰 쿼리

### 3)Expected Model Change

- 대표적인 방법은 Expected Gradient Length(EGL) 전략
- 
### 4) Core-set

### 5) Learning Loss

## Text Classification에서의 적용
A Survey of Active Learning for Text Classification using Deep Neural Networks (https://arxiv.org/abs/2008.07267)

![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/e0cc4df1-2fc8-40e6-aa8d-fa8f39806b26/Untitled.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/e0cc4df1-2fc8-40e6-aa8d-fa8f39806b26/Untitled.png)

- 위의 논문에 따르면 Query Strategy는 크게 Data-based, Model-based, Prediction-based로 나뉠 수 있음 (연구자에 따라 나누는 기준은 달라질 수 있음)

![AL/Untitled%2015.png](AL/Untitled%2015.png)

- 그 중 Text Classifcation에 자주 사용되는 방법은 **Prediction-Based의 Uncertainty sampling과 Prediction-Based의 disagreement (**Query by committee)이고 2가지 방법을 중점으로 실험 진행

# 2. AL for NLP

- 기존에 실험에서 좋은 성능으 보였던 Least Confidence Sampling(LC)을 적용 가능한 task 탐색
- **최근 AL 기법의 발전들은 CNN을 이용하는 Vision 분야에서 이루어짐.**  NLP 분야에서는 아직 연구가 많지 않은 상황. 바로 적용하기에 적절하지 않은 기법들도 있음

## 2.1 NER

- BERT NER fine-tuning에 직접적으로 active learning을 적용한 사례는 찾아보기 힘들었지만 NER에 LC를 적용한 사례는 위의 논문에서 찾을 수 있었음
- sequential하게 classifier를 계속 사용하는 것을 제외하면 classificaton과 동일하게 적용

- xij = i th word, j th character
각각의 NER을 예측하는 신뢰도가 가장 떨어지는 문장을 선택

- 또한 LC 기법을 조금 변형해서 사용하기도 함

## 2.2 MRC

- MRC에서도 마찬가지로 BERT fine-tuning에 직접적으로 active learning을 적용한 사례는 찾아보기 힘들었음

Uncertainty-Based Adaptive Learning for Reading Comprehension(https://openreview.net/forum?id=s4D2nnwCcM)

- 위의 논문은 아직 review 중인 논문이지만 BERT MRC fine-tuning에 AL 기법을 적용한 논문

- MRC 또한 start token과 end token에 대한 classification 형태로 진행이 되기 때문에 유사하게 적용 할 수 있음

## 2.3 Summarization

- 레퍼런스 없음
